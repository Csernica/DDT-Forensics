{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20241014_45_DDT_25uM_RES_235_1.txt\n",
      "20241014_46_DDT_25uM_RES_235_17_1.txt\n",
      "File 1 235 37Cl-37Cl-13C/Unsub fails RSE/SN Test with value of 11.074218681518625\n"
     ]
    }
   ],
   "source": [
    "#Separate processing script for DDT 17. \n",
    "\n",
    "#search for import above the current directory\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "cwd = Path().resolve().parent\n",
    "\n",
    "sys.path.insert(1, os.path.join(cwd, 'Read Process FT Stat'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import dataAnalyzer_FTStat\n",
    "import dataScreen_FTStat\n",
    "\n",
    "#Folder with FT Statistic-ified files. All the files need to be processed using the same metrics.\n",
    "fragKey = '235'\n",
    "cullTimes = {\n",
    "             #'20241027_235_40':(19, 40) run once with this to determine bounds, then fill in and repeat\n",
    "             #'20241027_235_17':(19.23, 24.62)}\n",
    "             '20241027_235_17':(19., 30)}\n",
    "\n",
    "allFragmentDict = {'20241027_235_17':{'235':['Unsub','13C','37Cl','37Cl-13C','37Cl-37Cl','37Cl-37Cl-13C']}}\n",
    "\n",
    "outDict = {}\n",
    "allMergedDict = {}\n",
    "for folderPath, thisCullTimes in cullTimes.items():\n",
    "    fragmentDict = allFragmentDict[folderPath]\n",
    "\n",
    "    fragmentMostAbundant = ['Unsub']\n",
    "\n",
    "    massStr = []\n",
    "    fragmentIsotopeList = []\n",
    "    for i, v in fragmentDict.items():\n",
    "        massStr.append(i)\n",
    "        fragmentIsotopeList.append(v)\n",
    "        \n",
    "    cullByTime = True\n",
    "    cullTimes = [thisCullTimes]\n",
    "\n",
    "    rtnAllFilesDF, mergedDict, allOutputDict = dataAnalyzer_FTStat.calc_Folder_Output(folderPath, cullOn=\"TIC*IT\",cullAmount = 3,\n",
    "                                                cullByTime=True, cullTimes = cullTimes, \n",
    "                                                fragmentIsotopeList = fragmentIsotopeList, \n",
    "                                                fragmentMostAbundant = fragmentMostAbundant, debug = True, fileExt = '.txt', \n",
    "                                                massStrList = list(fragmentDict.keys()),\n",
    "                                                Microscans = 1,\n",
    "                                                minNL_over_maxNL = 0.2,\n",
    "                                                cull_on_IT = 3000)\n",
    "    \n",
    "    dataScreen_FTStat.zeroCountsScreen(mergedDict, fragmentDict[fragKey])\n",
    "    dataScreen_FTStat.RSESNScreen(allOutputDict)\n",
    "    \n",
    "    outDict[folderPath] = rtnAllFilesDF\n",
    "    allMergedDict[folderPath] = copy.deepcopy(mergedDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleOutputDict = dataAnalyzer_FTStat.folderOutputToDict(rtnAllFilesDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1268786339840913]\n",
      "[1.345400522292812]\n",
      "[15.638362062758732]\n",
      "[1.2952192551624773]\n",
      "[0.6776216510052516]\n"
     ]
    }
   ],
   "source": [
    "# Extract subKeys for plotting\n",
    "file_keys = list(sampleOutputDict.keys())\n",
    "sub_keys = list(sampleOutputDict[file_keys[0]][fragKey].keys())\n",
    "\n",
    "storedValues = {}\n",
    "\n",
    "for i, sub_key in enumerate(sub_keys):\n",
    "    # Select the data for one subKey ('13C/Unsub') across all files\n",
    "    averages = [sampleOutputDict[file]['235'][sub_key]['Average'] for file in sampleOutputDict]\n",
    "    rel_std_errors = [sampleOutputDict[file]['235'][sub_key]['RelStdError'] for file in sampleOutputDict]\n",
    "\n",
    "    # Indices for samples\n",
    "    sample_indices = [1]\n",
    "\n",
    "    # Initialize lists for standardized values and propagated errors\n",
    "    standardized_deltas = []\n",
    "    propagated_errors = []\n",
    "\n",
    "    # Function to calculate the propagated error\n",
    "    def calculate_propagated_error(sample_error, std1_error, std2_error):\n",
    "        return np.sqrt(sample_error**2 + 1/ np.sqrt(2) * (std1_error/2 + std2_error/2)**2)\n",
    "\n",
    "    # Iterate through sample indices to calculate standardized values and errors\n",
    "    for idx in sample_indices:\n",
    "        sample_value = averages[idx]\n",
    "        std1_value = averages[idx - 1]\n",
    "        \n",
    "        standardized_value = sample_value / std1_value\n",
    "        standardized_delta = 1000 * (standardized_value-1)\n",
    "        \n",
    "        sample_error = rel_std_errors[idx]\n",
    "        std1_error = rel_std_errors[idx - 1]\n",
    "        \n",
    "        propagated_error = np.sqrt(sample_error**2 + std1_error**2)\n",
    "        propagated_error*= 1000\n",
    "        \n",
    "        standardized_deltas.append(standardized_delta)\n",
    "        propagated_errors.append(propagated_error)\n",
    "        print(propagated_errors)\n",
    "\n",
    "    storedValues[sub_key] = {'Deltas': copy.deepcopy(standardized_deltas), 'Errors':copy.deepcopy(propagated_errors)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "#Get json output\n",
    "\n",
    "folder_key = '20241027_235_17'\n",
    "output_dict = {folder_key: {}}\n",
    "\n",
    "for sub_key, values in storedValues.items():\n",
    "    deltas = values['Deltas']\n",
    "    errors = values['Errors']\n",
    "    \n",
    "    mean_delta = float(np.mean(deltas))\n",
    "    reproducibility = float(np.std(deltas, ddof=0))  # Will be 0.0 for 1 value\n",
    "\n",
    "    output_dict[folder_key][sub_key] = {\n",
    "        'Deltas': deltas,\n",
    "        'Propagated Acquisition Errors': errors,\n",
    "        'Mean Delta': mean_delta,\n",
    "        'Experimental Reproducibility': reproducibility,\n",
    "        'Mean Experimental Reproducibility': reproducibility\n",
    "    }\n",
    "\n",
    "# Save to JSON\n",
    "with open('20241027_235_17_results.json', 'w') as f:\n",
    "    json.dump(output_dict, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Orbitrap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
