{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search for import above the current directory\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "cwd = Path().resolve().parent\n",
    "\n",
    "sys.path.insert(1, os.path.join(cwd, 'Read Process FT Stat'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import dataAnalyzer_FTStat\n",
    "import dataScreen_FTStat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240801_120_DDT_SIG_EI_Reservoir_316_1e6_1.txt\n",
      "20240801_121_DDT_SIG_EI_Reservoir_316_1e6_2.txt\n",
      "20240801_122_DDT_SIG_EI_Reservoir_316_1e6_3.txt\n",
      "20240801_123_DDT_SIG_EI_Reservoir_316_1e6_4.txt\n",
      "20240801_124_DDT_SIG_EI_Reservoir_316_1e6_5.txt\n",
      "20240801_125_DDT_SIG_EI_Reservoir_316_1e6_6.txt\n",
      "20240801_126_DDT_SIG_EI_Reservoir_316_1e6_7.txt\n",
      "20240802_137_DDT_SIG_EI_316_1.txt\n",
      "20240802_138_DDT_LGC_EI_316_2.txt\n",
      "20240802_139_DDT_SIG_EI_316_3.txt\n",
      "20240802_140_DDT_LGC_EI_316_4.txt\n",
      "20240802_141_DDT_SIG_EI_316_5.txt\n",
      "20240802_142_DDT_LGC_EI_316_6.txt\n",
      "20240802_143_DDT_SIG_EI_316_7.txt\n",
      "20240802_158_DDT_SIG_EI_Reservoir_316_1.txt\n",
      "20240802_159_DDT_AGI_EI_Reservoir_316_2.txt\n",
      "20240802_160_DDT_SIG_EI_Reservoir_316_3.txt\n",
      "20240802_161_DDT_AGI_EI_Reservoir_316_4.txt\n",
      "20240802_162_DDT_SIG_EI_Reservoir_316_5.txt\n",
      "20240802_163_DDT_AGI_EI_Reservoir_316_6.txt\n",
      "20240802_164_DDT_SIG_EI_Reservoir_316_7.txt\n",
      "20241014_52_DDT_25uM_RES_316.txt\n",
      "20241014_53_DDT_40_RES_316_1.txt\n",
      "20241014_54_DDT_25uM_RES_316_2.txt\n",
      "20241014_60_DDT_25uM_RES_316_1.txt\n",
      "20241014_61_DDT_40_RES_316_1.txt\n",
      "20241014_62_DDT_25uM_RES_316_2.txt\n",
      "20241014_63_DDT_40_RES_316_2.txt\n",
      "20241014_64_DDT_25uM_RES_316_3.txt\n",
      "20241014_40_DDT_25uM_RES_316.txt\n",
      "20241014_41_DDT_25uM_RES_316_17_1.txt\n",
      "20241014_42_DDT_25uM_RES_316_2.txt\n",
      "20241014_43_DDT_25uM_RES_316_17_2.txt\n",
      "20241014_44_DDT_25uM_RES_316_3.txt\n"
     ]
    }
   ],
   "source": [
    "#Folder with FT Statistic-ified files. All the files need to be processed using the same metrics.\n",
    "fragKey = '316'\n",
    "toProcess = {'20240801_316_ZeroEnrichment':{'smp Indices':[1,3,5]},\n",
    "             '20240802_316_LGC':{'smp Indices':[1,3,5]},\n",
    "             '20240802_316_AGI':{'smp Indices':[1,3,5]},\n",
    "             '20241027_316_40':{'smp Indices':[1,4,6]},\n",
    "             '20241027_316_17':{'smp Indices':[1,3]}}\n",
    "\n",
    "outDict = {}\n",
    "allMergedDict = {}\n",
    "for folderPath, thisFolderParams in toProcess.items():\n",
    "    fragmentDict = {'316':['Unsub','37Cl','37Cl-37Cl','37Cl-37Cl-37Cl']}\n",
    "    fragmentMostAbundant = ['Unsub']\n",
    "\n",
    "    massStr = []\n",
    "    fragmentIsotopeList = []\n",
    "    for i, v in fragmentDict.items():\n",
    "        massStr.append(i)\n",
    "        fragmentIsotopeList.append(v)\n",
    "        \n",
    "    cullByTime = True\n",
    "    cullTimes = [(19.0,40.0)]\n",
    "    #If cullTime left bound is <19.0, can mess with the program to determine cull times by identifying an abundant 'Unsub' peak eluting before the valves have been switched, e.g., due to another compound which makes the same fragment eluting earlier in direct elution mode\n",
    "\n",
    "    rtnAllFilesDF, mergedDict, allOutputDict = dataAnalyzer_FTStat.calc_Folder_Output(folderPath, cullOn='TIC*IT',cullAmount = 3, \n",
    "                                                cullByTime=True, cullTimes = cullTimes, \n",
    "                                                fragmentIsotopeList = fragmentIsotopeList, \n",
    "                                                fragmentMostAbundant = fragmentMostAbundant, debug = True, fileExt = '.txt', \n",
    "                                                massStrList = list(fragmentDict.keys()),\n",
    "                                                Microscans = 1,\n",
    "                                                minNL_over_maxNL = 0.2,\n",
    "                                                cull_on_IT = 3000)\n",
    "                                           \n",
    "    \n",
    "    dataScreen_FTStat.zeroCountsScreen(mergedDict, fragmentDict[fragKey])\n",
    "    dataScreen_FTStat.RSESNScreen(allOutputDict)\n",
    "    \n",
    "    outDict[folderPath] = rtnAllFilesDF\n",
    "    allMergedDict[folderPath] = copy.deepcopy(mergedDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240801_120_DDT_SIG_EI_Reservoir_316_1e6_1.txt\n",
      "(19.34, 27.57)\n",
      "1591\n",
      "20240801_121_DDT_SIG_EI_Reservoir_316_1e6_2.txt\n",
      "(19.36, 27.66)\n",
      "1618\n",
      "20240801_122_DDT_SIG_EI_Reservoir_316_1e6_3.txt\n",
      "(19.34, 27.58)\n",
      "1618\n",
      "20240801_123_DDT_SIG_EI_Reservoir_316_1e6_4.txt\n",
      "(19.35, 27.46)\n",
      "1608\n",
      "20240801_124_DDT_SIG_EI_Reservoir_316_1e6_5.txt\n",
      "(19.32, 27.42)\n",
      "1626\n",
      "20240801_125_DDT_SIG_EI_Reservoir_316_1e6_6.txt\n",
      "(19.34, 27.33)\n",
      "1599\n",
      "20240801_126_DDT_SIG_EI_Reservoir_316_1e6_7.txt\n",
      "(19.34, 27.23)\n",
      "1618\n",
      "20240802_137_DDT_SIG_EI_316_1.txt\n",
      "(19.33, 26.86)\n",
      "1598\n",
      "20240802_138_DDT_LGC_EI_316_2.txt\n",
      "(19.33, 26.65)\n",
      "1580\n",
      "20240802_139_DDT_SIG_EI_316_3.txt\n",
      "(19.33, 26.65)\n",
      "1585\n",
      "20240802_140_DDT_LGC_EI_316_4.txt\n",
      "(19.34, 26.6)\n",
      "1591\n",
      "20240802_141_DDT_SIG_EI_316_5.txt\n",
      "(19.32, 26.51)\n",
      "1585\n",
      "20240802_142_DDT_LGC_EI_316_6.txt\n",
      "(19.32, 26.39)\n",
      "1566\n",
      "20240802_143_DDT_SIG_EI_316_7.txt\n",
      "(19.32, 26.42)\n",
      "1577\n",
      "20240802_158_DDT_SIG_EI_Reservoir_316_1.txt\n",
      "(19.33, 27.45)\n",
      "1768\n",
      "20240802_159_DDT_AGI_EI_Reservoir_316_2.txt\n",
      "(19.37, 26.73)\n",
      "1630\n",
      "20240802_160_DDT_SIG_EI_Reservoir_316_3.txt\n",
      "(19.33, 26.53)\n",
      "1626\n",
      "20240802_161_DDT_AGI_EI_Reservoir_316_4.txt\n",
      "(19.36, 26.39)\n",
      "1595\n",
      "20240802_162_DDT_SIG_EI_Reservoir_316_5.txt\n",
      "(19.33, 26.23)\n",
      "1575\n",
      "20240802_163_DDT_AGI_EI_Reservoir_316_6.txt\n",
      "(19.38, 25.99)\n",
      "1510\n",
      "20240802_164_DDT_SIG_EI_Reservoir_316_7.txt\n",
      "(19.32, 26.01)\n",
      "1528\n",
      "20241014_52_DDT_25uM_RES_316.txt\n",
      "(19.42, 22.52)\n",
      "90\n",
      "20241014_53_DDT_40_RES_316_1.txt\n",
      "(19.31, 21.89)\n",
      "72\n",
      "20241014_54_DDT_25uM_RES_316_2.txt\n",
      "(19.41, 22.32)\n",
      "83\n",
      "20241014_60_DDT_25uM_RES_316_1.txt\n",
      "(19.46, 21.7)\n",
      "59\n",
      "20241014_61_DDT_40_RES_316_1.txt\n",
      "(19.33, 21.6)\n",
      "62\n",
      "20241014_62_DDT_25uM_RES_316_2.txt\n",
      "(19.45, 21.66)\n",
      "59\n",
      "20241014_63_DDT_40_RES_316_2.txt\n",
      "(19.3, 21.81)\n",
      "70\n",
      "20241014_64_DDT_25uM_RES_316_3.txt\n",
      "(19.44, 21.75)\n",
      "61\n",
      "20241014_40_DDT_25uM_RES_316.txt\n",
      "(19.41, 22.98)\n",
      "105\n",
      "20241014_41_DDT_25uM_RES_316_17_1.txt\n",
      "(19.02, 22.94)\n",
      "105\n",
      "20241014_42_DDT_25uM_RES_316_2.txt\n",
      "(19.42, 22.7)\n",
      "62\n",
      "20241014_43_DDT_25uM_RES_316_17_2.txt\n",
      "(19.02, 21.89)\n",
      "83\n",
      "20241014_44_DDT_25uM_RES_316_3.txt\n",
      "(19.48, 21.4)\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "#check bounds\n",
    "for thisExp, thisData in allMergedDict.items():\n",
    "\tfor thisFile, thisFileData in thisData.items():\n",
    "\t\tcDf = thisFileData[0]\n",
    "\t\tprint(thisFile)\n",
    "\t\tprint(str((cDf['retTime'].min(), cDf['retTime'].max())))\n",
    "\t\tprint(len(cDf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate standardized deltas and propagated errors.\n",
    "# \n",
    "allFolderValues = {}\n",
    "for folderPath, folderParams in toProcess.items():\n",
    "\tthisRtnAllFilesDf = outDict[folderPath]\n",
    "\tsampleOutputDict = dataAnalyzer_FTStat.folderOutputToDict(thisRtnAllFilesDf)\n",
    "\n",
    "\tfile_keys = list(sampleOutputDict.keys())\n",
    "\tsub_keys = list(sampleOutputDict[file_keys[0]][fragKey].keys())\n",
    "\t  \n",
    "\tthisFolderValues = {}\n",
    "\tfor subIdx, subKey in enumerate(sub_keys):\n",
    "\t\t# Select the data for one subKey ('13C/Unsub') across all files\n",
    "\t\taverages = [sampleOutputDict[file][fragKey][subKey]['Average'] for file in sampleOutputDict]\n",
    "\t\trel_std_errors = [sampleOutputDict[file][fragKey][subKey]['RelStdError'] for file in sampleOutputDict]\n",
    "\t\t\t\t\n",
    "\t\t# Indices for samples\n",
    "\t\tsample_indices = folderParams['smp Indices']\n",
    "\n",
    "\t\t# Initialize lists for standardized values and propagated errors\n",
    "\t\tstandardized_deltas = []\n",
    "\t\tpropagated_errors = []\n",
    "\n",
    "\t\t# Function to calculate the propagated error\n",
    "\t\tdef calculate_propagated_error(sample_error, std1_error, std2_error):\n",
    "\t\t\treturn np.sqrt(sample_error**2 + 1/np.sqrt(2) * (std1_error/2 + std2_error/2)**2)\n",
    "\n",
    "\t\t# Iterate through sample indices to calculate standardized values and errors\n",
    "\t\tfor idx in sample_indices:\n",
    "\t\t\tsample_value = averages[idx]\n",
    "\t\t\tstd1_value, std2_value = averages[idx - 1], averages[idx + 1]\n",
    "\t\t\t\n",
    "\t\t\tstandardized_value = (sample_value / std1_value + sample_value / std2_value) / 2\n",
    "\t\t\tstandardized_delta = 1000 * (standardized_value-1)\n",
    "\t\t\t\n",
    "\t\t\tsample_error = rel_std_errors[idx]\n",
    "\t\t\tstd1_error, std2_error = rel_std_errors[idx - 1], rel_std_errors[idx + 1]\n",
    "\t\t\t\n",
    "\t\t\tpropagated_error = calculate_propagated_error(sample_error, std1_error, std2_error)\n",
    "\t\t\tpropagated_error*= 1000\n",
    "\t\t\t\n",
    "\t\t\tstandardized_deltas.append(standardized_delta)\n",
    "\t\t\tpropagated_errors.append(propagated_error)\n",
    "\t\t\t\n",
    "\t\n",
    "\t\tthisFolderValues[subKey] = {'Deltas': copy.deepcopy(standardized_deltas), \n",
    "\t\t\t\t\t\t\t  'Propagated Acquisition Errors':copy.deepcopy(propagated_errors),\n",
    "\t\t\t\t\t\t\t  'Mean Delta' : np.array(standardized_deltas).mean(),\n",
    "\t\t\t\t\t\t\t  'Experimental Reproducibility': np.array(standardized_deltas).std()/ np.sqrt(len(standardized_deltas))}\n",
    "\t\t\n",
    "\tallFolderValues[folderPath] = thisFolderValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOUND\n",
      "FOUND\n"
     ]
    }
   ],
   "source": [
    "#Calculate experimental reproducibilities\n",
    "# --- Step 1: Collect all reproducibilities grouped by Ratio Key ---\n",
    "from collections import defaultdict\n",
    "\n",
    "grouped_repro = defaultdict(list)\n",
    "\n",
    "for folder, ratios in allFolderValues.items():\n",
    "    if folder in ['20241027_316_17', '20241027_316_40']:\n",
    "        print(\"FOUND\")\n",
    "        continue\n",
    "    for ratio_key, metrics in ratios.items():\n",
    "        grouped_repro[ratio_key].append(metrics['Experimental Reproducibility'])\n",
    "\n",
    "# --- Step 2: Compute mean for each Ratio Key ---\n",
    "mean_repro_by_key = {k: sum(v) / len(v) for k, v in grouped_repro.items()}\n",
    "\n",
    "# --- Step 3: Add it back to each entry ---\n",
    "for folder, ratios in allFolderValues.items():\n",
    "    for ratio_key, metrics in ratios.items():\n",
    "\n",
    "        if folder in ['20241027_316_17', '20241027_316_40']:\n",
    "            this_MR = metrics['Experimental Reproducibility']\n",
    "        else:\n",
    "            this_MR = mean_repro_by_key[ratio_key]\n",
    "        metrics['Mean Experimental Reproducibility'] = this_MR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save to JSON file\n",
    "with open('316_data.json', 'w') as f:\n",
    "    json.dump(allFolderValues, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37Cl-37Cl-37Cl/Unsub\n",
      "20.67325382182694\n",
      "2.6836092791104798\n",
      "37Cl-37Cl/Unsub\n",
      "10.993902772792774\n",
      "1.4479538798260592\n",
      "37Cl/Unsub\n",
      "2.2709849570804463\n",
      "1.2052053374162868\n"
     ]
    }
   ],
   "source": [
    "#Print values for file 17\n",
    "for ratio_key, ratio_data in allFolderValues['20241027_316_17'].items():\n",
    "    print(ratio_key)\n",
    "    this_prop_ae = np.mean(ratio_data['Propagated Acquisition Errors']) / np.sqrt(len(ratio_data['Propagated Acquisition Errors']))\n",
    "    this_error = max(this_prop_ae, ratio_data['Experimental Reproducibility'])\n",
    "    print(ratio_data['Mean Delta'])\n",
    "    print(this_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export to csv\n",
    "# Step 1: Flatten the data\n",
    "flattened_data = []\n",
    "for folder_name, ratios in allFolderValues.items():\n",
    "    for ratio_key, metrics in ratios.items():\n",
    "        entry = {\n",
    "            'Folder Name': folder_name,\n",
    "            'Ratio Key': ratio_key,\n",
    "            'Deltas': metrics['Deltas'],\n",
    "            'Propagated Acquisition Errors': metrics['Propagated Acquisition Errors'],\n",
    "            'Mean Delta': metrics['Mean Delta'],\n",
    "            'Experimental Reproducibility': metrics['Experimental Reproducibility']\n",
    "        }\n",
    "        flattened_data.append(entry)\n",
    "\n",
    "# Step 2: Create a pandas DataFrame\n",
    "df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Step 3: Expand lists into separate columns\n",
    "df = df.explode(['Deltas', 'Propagated Acquisition Errors']).reset_index(drop=True)\n",
    "\n",
    "# Step 4: Round numerical columns to three decimal places\n",
    "#Explode messes with the datatypes for these; fix\n",
    "df['Deltas'] = pd.to_numeric(df['Deltas'], errors='coerce')\n",
    "df['Propagated Acquisition Errors'] = pd.to_numeric(df['Propagated Acquisition Errors'], errors='coerce')\n",
    "#now round\n",
    "columns_to_round = ['Deltas', 'Propagated Acquisition Errors', 'Mean Delta', 'Experimental Reproducibility']\n",
    "df[columns_to_round] = df[columns_to_round].round(2)\n",
    "\n",
    "df.to_csv(\"316 Data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1.496834\n",
       "1     1.515544\n",
       "2     1.496834\n",
       "3     1.393171\n",
       "4     1.424131\n",
       "5     1.424131\n",
       "6     1.048347\n",
       "7     1.048347\n",
       "8     1.048347\n",
       "9     0.799408\n",
       "10    0.809790\n",
       "11    0.779423\n",
       "12    0.078730\n",
       "13    0.078730\n",
       "14    0.078730\n",
       "15    0.655371\n",
       "16    0.638124\n",
       "17    0.655371\n",
       "18    1.162297\n",
       "19    1.177795\n",
       "20    1.147202\n",
       "21    0.948504\n",
       "22    0.948504\n",
       "23    0.905390\n",
       "24    0.643333\n",
       "25    0.608558\n",
       "26    0.608558\n",
       "27    0.840703\n",
       "28    0.737232\n",
       "29    0.794255\n",
       "30    0.631388\n",
       "31    0.554856\n",
       "32    0.593388\n",
       "33    0.980800\n",
       "34    0.935706\n",
       "35    0.919846\n",
       "36    0.510929\n",
       "37    0.412393\n",
       "38    0.373580\n",
       "39    0.371757\n",
       "40    0.424632\n",
       "41    0.353860\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compare ER to PAE\n",
    "df['Experimental Reproducibility'] * np.sqrt(3) / df['Propagated Acquisition Errors']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Orbitrap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
